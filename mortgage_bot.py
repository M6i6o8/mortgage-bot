"""
–ò–ø–æ—Ç–µ—á–Ω—ã–π –±–æ—Ç - —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –º–Ω–æ–∂–µ—Å—Ç–≤–æ–º –ø—Ä–æ–∫—Å–∏-–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ –ø–∞—Ä—Å–∏–Ω–≥–æ–º –°—Ä–∞–≤–Ω–∏.—Ä—É
–ó–∞–ø—É—Å–∫ –Ω–∞ GitHub Actions
"""

import requests
from bs4 import BeautifulSoup
import re
from datetime import datetime
import os
import random
import time
import warnings

warnings.filterwarnings("ignore", category=DeprecationWarning)

# ===== –ù–ê–°–¢–†–û–ô–ö–ò =====
BOT_TOKEN = os.environ.get('BOT_TOKEN', '')
CHANNEL_ID = os.environ.get('CHANNEL_ID', '')

# ===== –†–ê–°–®–ò–†–ï–ù–ù–´–ô –ü–†–û–ö–°–ò-–ú–ï–ù–ï–î–ñ–ï–† =====
class AdvancedProxyManager:
    def __init__(self):
        self.proxies = []
        self.current_proxy = None
        self.update_proxy_list()
    
    def fetch_from_url(self, url, parser_func=None):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ–∫—Å–∏ —Å —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ URL"""
        try:
            print(f"    –ó–∞–≥—Ä—É–∂–∞–µ–º —Å {url[:50]}...")
            response = requests.get(url, timeout=10)
            
            if response.status_code == 200:
                if parser_func:
                    return parser_func(response.text)
                else:
                    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: –ø–æ—Å—Ç—Ä–æ—á–Ω–æ, —É–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                    return [line.strip() for line in response.text.strip().split('\n') if line.strip()]
            return []
        except Exception as e:
            print(f"    ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            return []
    
    def parse_proxyscrape(self, text):
        """–ü–∞—Ä—Å–∏—Ç —Ñ–æ—Ä–º–∞—Ç ProxyScrape (–ø—Ä–æ—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫)"""
        return [line.strip() for line in text.strip().split('\n') if line.strip()]
    
    def parse_github_raw(self, text):
        """–ü–∞—Ä—Å–∏—Ç —Å—ã—Ä—ã–µ —Å–ø–∏—Å–∫–∏ —Å GitHub"""
        proxies = []
        for line in text.strip().split('\n'):
            line = line.strip()
            if line and not line.startswith('#'):
                proxies.append(line)
        return proxies
    
    def update_proxy_list(self):
        """–ö–∞—á–∞–µ—Ç –ø—Ä–æ–∫—Å–∏ –∏–∑ –ú–ù–û–ñ–ï–°–¢–í–ê –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        print("  –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–∫—Å–∏ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤...")
        all_proxies = []
        
        # –ò–°–¢–û–ß–ù–ò–ö 1: ProxyScrape (–æ—Å–Ω–æ–≤–Ω–æ–π, —É–∂–µ —Ä–∞–±–æ—Ç–∞–µ—Ç)
        url1 = "https://api.proxyscrape.com/v2/?request=displayproxies&protocol=http&timeout=10000&country=RU&ssl=all&anonymity=all"
        proxies1 = self.fetch_from_url(url1)
        all_proxies.extend(proxies1)
        print(f"    ‚úÖ ProxyScrape: {len(proxies1)}")
        
        # –ò–°–¢–û–ß–ù–ò–ö 2: free-proxy-list.net [citation:7]
        url2 = "https://free-proxy-list.net/"
        try:
            response = requests.get(url2, timeout=10)
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                table = soup.find('table', {'id': 'proxylisttable'})
                if table:
                    rows = table.find_all('tr')[1:51]  # –ü–µ—Ä–≤—ã–µ 50 —Å—Ç—Ä–æ–∫
                    for row in rows:
                        cols = row.find_all('td')
                        if len(cols) >= 2:
                            ip = cols[0].text.strip()
                            port = cols[1].text.strip()
                            all_proxies.append(f"{ip}:{port}")
            print(f"    ‚úÖ free-proxy-list.net: {len(rows) if 'rows' in locals() else 0}")
        except Exception as e:
            print(f"    ‚ö†Ô∏è free-proxy-list.net: {e}")
        
        # –ò–°–¢–û–ß–ù–ò–ö 3: GitHub - GoekhanDev/free-proxy-list [citation:1]
        url3 = "https://raw.githubusercontent.com/GoekhanDev/free-proxy-list/main/http.txt"
        proxies3 = self.fetch_from_url(url3)
        all_proxies.extend(proxies3[:50])  # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 50
        print(f"    ‚úÖ GoekhanDev: {len(proxies3[:50])}")
        
        # –ò–°–¢–û–ß–ù–ò–ö 4: fresh-proxy-list –æ—Ç fyvri [citation:3]
        url4 = "https://raw.githubusercontent.com/fyvri/fresh-proxy-list/main/lists/http.txt"
        proxies4 = self.fetch_from_url(url4)
        all_proxies.extend(proxies4[:50])
        print(f"    ‚úÖ fresh-proxy-list: {len(proxies4[:50])}")
        
        # –ò–°–¢–û–ß–ù–ò–ö 5: proxifly [citation:10]
        url5 = "https://cdn.jsdelivr.net/gh/proxifly/free-proxy-list@main/proxies/protocols/http/data.txt"
        proxies5 = self.fetch_from_url(url5)
        all_proxies.extend(proxies5[:50])
        print(f"    ‚úÖ proxifly: {len(proxies5[:50])}")
        
        # –ò–°–¢–û–ß–ù–ò–ö 6: socketpy proxy-list-link [citation:9]
        url6 = "https://raw.githubusercontent.com/socketpy/proxy-list-link/main/proxies/http.txt"
        proxies6 = self.fetch_from_url(url6)
        all_proxies.extend(proxies6[:50])
        print(f"    ‚úÖ socketpy: {len(proxies6[:50])}")
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        unique_proxies = list(set([p for p in all_proxies if p and len(p.split(':')) == 2]))
        
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—á–∏–µ (–ø—Ä–∏–º–µ—Ä–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç)
        valid_proxies = []
        for proxy in unique_proxies:
            parts = proxy.split(':')
            if len(parts) == 2 and parts[0].count('.') == 3:
                valid_proxies.append(proxy)
        
        self.proxies = valid_proxies[:100]  # –•—Ä–∞–Ω–∏–º –¥–æ 100 –ª—É—á—à–∏—Ö
        print(f"    ‚úÖ –í–°–ï–ì–û –£–ù–ò–ö–ê–õ–¨–ù–´–•: {len(self.proxies)}")
    
    def get_random_proxy(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π –ø—Ä–æ–∫—Å–∏ –∏–∑ —Å–ø–∏—Å–∫–∞"""
        if not self.proxies:
            self.update_proxy_list()
        
        if self.proxies:
            self.current_proxy = random.choice(self.proxies)
            return {
                'http': f'http://{self.current_proxy}',
                'https': f'http://{self.current_proxy}'
            }
        return None
    
    def report_failure(self):
        """–°–æ–æ–±—â–∞–µ–º, —á—Ç–æ —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–∫—Å–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç"""
        if self.current_proxy and self.current_proxy in self.proxies:
            self.proxies.remove(self.current_proxy)
        self.current_proxy = None

# ===== –ü–ê–†–°–ï–† =====
class BankiRuParser:
    def __init__(self):
        self.all_rates = {}
        self.proxy_manager = AdvancedProxyManager()
        
        # –ó–∞–ø–∞—Å–Ω—ã–µ —Å—Ç–∞–≤–∫–∏
        self.fallback_rates = {
            '–°–±–µ—Ä–±–∞–Ω–∫': 21.0,
            '–í–¢–ë': 20.1,
            '–ê–ª—å—Ñ–∞-–ë–∞–Ω–∫': 20.5,
            '–¢-–ë–∞–Ω–∫': 16.9,
            '–ë–∞–Ω–∫ –î–û–ú.–†–§': 20.2,
            '–ë–∞–Ω–∫ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥': 18.49,
            '–£—Ä–∞–ª—Å–∏–±': 18.79,
            '–ü—Ä–æ–º—Å–≤—è–∑—å–±–∞–Ω–∫': 19.49,
            '–¢—Ä–∞–Ω—Å–∫–∞–ø–∏—Ç–∞–ª–±–∞–Ω–∫': 20.25,
            '–í–ë–†–†': 20.4,
            '–ì–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫': 20.8,
            '–†–æ—Å—Å–µ–ª—å—Ö–æ–∑–±–∞–Ω–∫': 20.2,
            '–°–æ–≤–∫–æ–º–±–∞–Ω–∫': 20.9,
            '–ë–∞–Ω–∫ –û—Ç–∫—Ä—ã—Ç–∏–µ': 21.1,
            '–ú–¢–° –ë–∞–Ω–∫': 20.7,
        }
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –∫–∞–∫ —É —Ä–µ–∞–ª—å–Ω–æ–≥–æ –±—Ä–∞—É–∑–µ—Ä–∞
        self.headers = {
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
    
    def get_random_user_agent(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π User-Agent"""
        ua_list = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
        ]
        return random.choice(ua_list)
    
    def extract_rate(self, text):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å–ª–æ-—Å—Ç–∞–≤–∫—É –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return None
        
        patterns = [
            r'–æ—Ç\s*(\d+[.,]\d+)%',
            r'(\d+[.,]\d+)%\s*–≥–æ–¥–æ–≤—ã—Ö',
            r'(\d+[.,]\d+)%',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                rate_str = match.group(1).replace(',', '.')
                try:
                    rate = float(rate_str)
                    if 5 <= rate <= 35:
                        return rate
                except:
                    continue
        return None
    
    def parse_sravni_ru(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –°—Ä–∞–≤–Ω–∏.—Ä—É - –ù–û–í–´–ô –ò–°–¢–û–ß–ù–ò–ö"""
        try:
            print("  –ü–∞—Ä—Å–∏–º –°—Ä–∞–≤–Ω–∏.—Ä—É...")
            url = "https://www.sravni.ru/ipoteka/"
            
            # –ü—Ä–æ–±—É–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏ —Å–Ω–∞—á–∞–ª–∞
            headers = self.headers.copy()
            headers['User-Agent'] = self.get_random_user_agent()
            
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                found_banks = 0
                
                # –ò—â–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ –±–∞–Ω–∫–æ–≤ (—Å–µ–ª–µ–∫—Ç–æ—Ä—ã –Ω—É–∂–Ω–æ –ø–æ–¥–±–∏—Ä–∞—Ç—å –ø–æ–¥ –≤–µ—Ä—Å—Ç–∫—É –°—Ä–∞–≤–Ω–∏.—Ä—É)
                bank_cards = soup.find_all('div', class_=re.compile('product-item|bank-card|offer'))
                
                if not bank_cards:
                    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫
                    bank_cards = soup.find_all('article', class_=re.compile('product'))
                
                for card in bank_cards[:15]:
                    try:
                        card_text = card.get_text()
                        
                        # –ò—â–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –±–∞–Ω–∫–∞
                        bank_match = re.search(r'([–ê-–Ø][–∞-—è]+(?:\s+[–ê-–Ø][–∞-—è]+)*)', card_text)
                        if not bank_match:
                            continue
                        
                        bank_name = bank_match.group(1).strip()
                        
                        # –ò—â–µ–º —Å—Ç–∞–≤–∫—É
                        rate = self.extract_rate(card_text)
                        
                        if bank_name and rate and len(bank_name) < 40:
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ª—å–≥–æ—Ç–Ω–∞—è –ª–∏ —Å—Ç–∞–≤–∫–∞
                            if '–ª—å–≥–æ—Ç' not in card_text.lower() and '—Å–µ–º–µ–π–Ω' not in card_text.lower():
                                self.all_rates[bank_name] = rate
                                found_banks += 1
                                print(f"    ‚úì {bank_name}: {rate}% (–°—Ä–∞–≤–Ω–∏.—Ä—É)")
                                
                    except Exception:
                        continue
                
                if found_banks > 0:
                    print(f"    ‚úÖ –°—Ä–∞–≤–Ω–∏.—Ä—É: –Ω–∞–π–¥–µ–Ω–æ {found_banks} –±–∞–Ω–∫–æ–≤")
                    return True
                else:
                    print("    ‚ö†Ô∏è –°—Ä–∞–≤–Ω–∏.—Ä—É: –±–∞–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                    return False
            else:
                print(f"    ‚ö†Ô∏è –°—Ä–∞–≤–Ω–∏.—Ä—É: —Å—Ç–∞—Ç—É—Å {response.status_code}")
                return False
                
        except Exception as e:
            print(f"    ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –°—Ä–∞–≤–Ω–∏.—Ä—É: {e}")
            return False
    
    def parse_banki_ru(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –ë–∞–Ω–∫–∏.—Ä—É —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏"""
        try:
            print("  –ü–∞—Ä—Å–∏–º –ë–∞–Ω–∫–∏.—Ä—É —Å –ø—Ä–æ–∫—Å–∏...")
            
            # –ü—Ä–æ–±—É–µ–º –¥–æ 5 —Ä–∞–∑–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏
            for attempt in range(5):
                proxy = self.proxy_manager.get_random_proxy()
                if not proxy:
                    print("    ‚ö†Ô∏è –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏")
                    return False
                
                print(f"    –ü–æ–ø—ã—Ç–∫–∞ {attempt+1}, –ø—Ä–æ–∫—Å–∏: {proxy['http']}")
                
                headers = self.headers.copy()
                headers['User-Agent'] = self.get_random_user_agent()
                
                try:
                    session = requests.Session()
                    session.proxies.update(proxy)
                    session.headers.update(headers)
                    
                    # –ó–∞—Ö–æ–¥–∏–º –Ω–∞ –≥–ª–∞–≤–Ω—É—é
                    session.get('https://www.banki.ru/', timeout=10)
                    time.sleep(1)
                    
                    # –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –∏–ø–æ—Ç–µ–∫–æ–π
                    url = "https://www.banki.ru/products/ipoteka/"
                    response = session.get(url, timeout=10)
                    
                    if response.status_code == 200:
                        soup = BeautifulSoup(response.text, 'html.parser')
                        
                        found_banks = 0
                        rows = soup.find_all('tr', {'data-test': 'row'})
                        
                        if not rows:
                            rows = soup.find_all('tr', class_=re.compile('row|product'))
                        
                        for row in rows[:20]:
                            try:
                                row_text = row.get_text()
                                bank_match = re.search(r'([–ê-–Ø][–∞-—è]+(?:\s+[–ê-–Ø][–∞-—è]+)*)', row_text)
                                if not bank_match:
                                    continue
                                
                                bank_name = bank_match.group(1).strip()
                                rate = self.extract_rate(row_text)
                                
                                if bank_name and rate and len(bank_name) < 40:
                                    self.all_rates[bank_name] = rate
                                    found_banks += 1
                                    print(f"    ‚úì {bank_name[:30]}: {rate}% (–ë–∞–Ω–∫–∏.—Ä—É)")
                                    
                            except Exception:
                                continue
                        
                        if found_banks > 0:
                            print(f"    ‚úÖ –ë–∞–Ω–∫–∏.—Ä—É: –Ω–∞–π–¥–µ–Ω–æ {found_banks} –±–∞–Ω–∫–æ–≤")
                            return True
                        else:
                            print(f"    ‚ö†Ô∏è –ë–∞–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–æ–π –ø—Ä–æ–∫—Å–∏")
                            self.proxy_manager.report_failure()
                            
                    else:
                        print(f"    ‚ö†Ô∏è –°—Ç–∞—Ç—É—Å {response.status_code}")
                        self.proxy_manager.report_failure()
                        
                except Exception as e:
                    print(f"    ‚ö†Ô∏è –û—à–∏–±–∫–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏: {e}")
                    self.proxy_manager.report_failure()
                    
                time.sleep(1)
            
            return False
                    
        except Exception as e:
            print(f"    ‚úó –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            return False
    
    def parse_individual_banks(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –±–∞–Ω–∫–æ–≤"""
        
        # –°–±–µ—Ä
        try:
            print("  –ü–∞—Ä—Å–∏–º –°–±–µ—Ä...")
            url = "https://www.sberbank.ru/ru/person/credits/home/buying_complete_house"
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                rate = self.extract_rate(response.text)
                if rate:
                    self.all_rates['–°–±–µ—Ä–±–∞–Ω–∫'] = rate
                    print(f"    ‚úì –°–±–µ—Ä: {rate}%")
        except:
            pass
        
        time.sleep(1)
        
        # –í–¢–ë
        try:
            print("  –ü–∞—Ä—Å–∏–º –í–¢–ë...")
            url = "https://www.vtb.ru/personal/ipoteka/"
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                rate = self.extract_rate(response.text)
                if rate:
                    self.all_rates['–í–¢–ë'] = rate
                    print(f"    ‚úì –í–¢–ë: {rate}%")
        except:
            pass
        
        time.sleep(1)
        
        # –ê–ª—å—Ñ–∞
        try:
            print("  –ü–∞—Ä—Å–∏–º –ê–ª—å—Ñ–∞-–ë–∞–Ω–∫...")
            url = "https://alfabank.ru/get-money/mortgage/"
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                rate = self.extract_rate(response.text)
                if rate:
                    self.all_rates['–ê–ª—å—Ñ–∞-–ë–∞–Ω–∫'] = rate
                    print(f"    ‚úì –ê–ª—å—Ñ–∞-–ë–∞–Ω–∫: {rate}%")
        except:
            pass
    
    def add_fallback_rates(self):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∑–∞–ø–∞—Å–Ω—ã–µ —Å—Ç–∞–≤–∫–∏"""
        added = 0
        for bank, rate in self.fallback_rates.items():
            if bank not in self.all_rates:
                self.all_rates[bank] = rate
                added += 1
        
        if added > 0:
            print(f"    ‚ûï –î–æ–±–∞–≤–ª–µ–Ω–æ –∑–∞–ø–∞—Å–Ω—ã—Ö –±–∞–Ω–∫–æ–≤: {added}")
    
    def collect_all_rates(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ –ø–∞—Ä—Å–µ—Ä—ã"""
        print("  –ó–∞–ø—É—Å–∫–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥...")
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –°—Ä–∞–≤–Ω–∏.—Ä—É (–Ω–æ–≤—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫, –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ—â–µ)
        sravni_success = self.parse_sravni_ru()
        time.sleep(2)
        
        # –ü–æ—Ç–æ–º –ë–∞–Ω–∫–∏.—Ä—É —Å –ø—Ä–æ–∫—Å–∏
        banki_success = self.parse_banki_ru()
        
        if not banki_success and not sravni_success:
            print("  ‚ö†Ô∏è –ê–≥—Ä–µ–≥–∞—Ç–æ—Ä—ã –Ω–µ —Å–ø–∞—Ä—Å–∏–ª–∏—Å—å, –ø–∞—Ä—Å–∏–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ –±–∞–Ω–∫–∏...")
            self.parse_individual_banks()
        else:
            time.sleep(1)
            self.parse_individual_banks()  # –î–ª—è —Å–≤–µ—Ä–∫–∏
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∞—Å–Ω—ã–µ
        self.add_fallback_rates()
        
        return self.all_rates

# ===== –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï =====
def format_message(rates_dict):
    if not rates_dict:
        return "üòî –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–≤–∫–∏"
    
    rates_list = [(bank, rate) for bank, rate in rates_dict.items()]
    rates_list.sort(key=lambda x: x[1])
    
    top_rates = rates_list[:20]
    min_bank, min_rate = rates_list[0]
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    has_banki = any('–±–∞–Ω–∫–∏' in b.lower() for b, _ in rates_list[:5])
    has_sravni = any('—Å—Ä–∞–≤–Ω–∏' in b.lower() for b, _ in rates_list[:5])
    
    sources = []
    if has_banki:
        sources.append("–ë–∞–Ω–∫–∏.—Ä—É")
    if has_sravni:
        sources.append("–°—Ä–∞–≤–Ω–∏.—Ä—É")
    
    source_text = f"–ò—Å—Ç–æ—á–Ω–∏–∫–∏: {', '.join(sources)}" if sources else "–ò—Å—Ç–æ—á–Ω–∏–∫–∏: –∑–∞–ø–∞—Å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"
    
    text = f"""
üè† <b>–ò–ø–æ—Ç–µ–∫–∞ —Å–µ–≥–æ–¥–Ω—è: –ú–ò–ù–ò–ú–ê–õ–¨–ù–ê–Ø –°–¢–ê–í–ö–ê</b>

üî• <b>–õ—É—á—à–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ:</b>
‚Ä¢ {min_bank} ‚Äî <b>{min_rate}%</b>

üìä <b>–í—Å–µ –±–∞–Ω–∫–∏:</b>

"""
    
    for i, (bank, rate) in enumerate(top_rates, 1):
        if i == 1:
            text += f"ü•á {bank} ‚Äî {rate}%\n"
        elif i == 2:
            text += f"ü•à {bank} ‚Äî {rate}%\n"
        elif i == 3:
            text += f"ü•â {bank} ‚Äî {rate}%\n"
        else:
            text += f"‚Ä¢ {bank} ‚Äî {rate}%\n"
    
    text += f"""

üìÖ {datetime.now().strftime('%d.%m.%Y %H:%M')} (–ú–°–ö)
üìä –í—Å–µ–≥–æ: {len(rates_list)} –±–∞–Ω–∫–æ–≤
üîÑ {source_text}
"""
    
    return text

# ===== –û–¢–ü–†–ê–í–ö–ê =====
def send_to_channel(text):
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    data = {
        "chat_id": CHANNEL_ID,
        "text": text,
        "parse_mode": "HTML"
    }
    
    try:
        response = requests.post(url, data=data, timeout=10)
        if response.status_code == 200:
            print("  ‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ!")
    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")

# ===== –ì–õ–ê–í–ù–ê–Ø =====
def main():
    print("=" * 60)
    print("üöÄ –ó–ê–ü–£–°–ö –†–ê–°–®–ò–†–ï–ù–ù–û–ì–û –ü–ê–†–°–ò–ù–ì–ê")
    print(f"üìÖ {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}")
    print("=" * 60)
    
    if not BOT_TOKEN or not CHANNEL_ID:
        print("‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫")
        return
    
    parser = BankiRuParser()
    rates = parser.collect_all_rates()
    
    print(f"\nüìä –í—Å–µ–≥–æ: {len(rates)} –±–∞–Ω–∫–æ–≤")
    message = format_message(rates)
    send_to_channel(message)
    print("\n‚úÖ –ì–û–¢–û–í–û")

if __name__ == "__main__":
    main()