"""
–ò–ø–æ—Ç–µ—á–Ω—ã–π –±–æ—Ç - –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–ê–Ø –í–ï–†–°–ò–Ø —Å 7 –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö
–ó–∞–ø—É—Å–∫ –Ω–∞ GitHub Actions
"""

import requests
from bs4 import BeautifulSoup
import re
from datetime import datetime
import os
import random
import time
import warnings
import json

warnings.filterwarnings("ignore", category=DeprecationWarning)

# ===== –ù–ê–°–¢–†–û–ô–ö–ò =====
BOT_TOKEN = os.environ.get('BOT_TOKEN', '')
CHANNEL_ID = os.environ.get('CHANNEL_ID', '')

# ===== –ü–†–û–ö–°–ò-–ú–ï–ù–ï–î–ñ–ï–† =====
class ProxyManager:
    def __init__(self):
        self.proxies = []
        self.current_proxy = None
        self.update_proxy_list()
    
    def fetch_proxies(self, url):
        try:
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                return [line.strip() for line in response.text.strip().split('\n') if line.strip()]
            return []
        except:
            return []
    
    def update_proxy_list(self):
        """–ö–∞—á–∞–µ—Ç –ø—Ä–æ–∫—Å–∏ –∏–∑ 5 –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        print("  –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–∫—Å–∏...")
        all_proxies = []
        
        # –ò—Å—Ç–æ—á–Ω–∏–∫ 1: ProxyScrape
        proxies1 = self.fetch_proxies("https://api.proxyscrape.com/v2/?request=displayproxies&protocol=http&timeout=10000&country=RU&ssl=all")
        all_proxies.extend(proxies1)
        
        # –ò—Å—Ç–æ—á–Ω–∏–∫ 2: GoekhanDev
        proxies2 = self.fetch_proxies("https://raw.githubusercontent.com/GoekhanDev/free-proxy-list/main/http.txt")
        all_proxies.extend(proxies2)
        
        # –ò—Å—Ç–æ—á–Ω–∏–∫ 3: proxifly
        proxies3 = self.fetch_proxies("https://raw.githubusercontent.com/proxifly/free-proxy-list/main/proxies/protocols/http/data.txt")
        all_proxies.extend(proxies3)
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        self.proxies = list(set(all_proxies))[:50]
        print(f"    ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø—Ä–æ–∫—Å–∏: {len(self.proxies)}")
    
    def get_proxy(self):
        if not self.proxies:
            self.update_proxy_list()
        
        if self.proxies:
            proxy = random.choice(self.proxies)
            return {
                'http': f'http://{proxy}',
                'https': f'http://{proxy}'
            }
        return None
    
    def report_bad(self, proxy):
        if proxy and proxy in self.proxies:
            self.proxies.remove(proxy)

# ===== –ü–ê–†–°–ï–† =====
class MegaParser:
    def __init__(self):
        self.all_rates = {}
        self.proxy_manager = ProxyManager()
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏
        self.headers = {
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
            'Connection': 'keep-alive',
        }
    
    def get_ua(self):
        ua_list = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/121.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 Safari/605.1.15',
        ]
        return random.choice(ua_list)
    
    def extract_rate(self, text):
        if not text:
            return None
        
        patterns = [
            r'–æ—Ç\s*(\d+[.,]\d+)%',
            r'(\d+[.,]\d+)%\s*–≥–æ–¥–æ–≤—ã—Ö',
            r'(\d+[.,]\d+)%',
            r'—Å—Ç–∞–≤–∫–∞[^\d]*(\d+[.,]\d+)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                rate_str = match.group(1).replace(',', '.')
                try:
                    rate = float(rate_str)
                    if 5 <= rate <= 35:
                        return rate
                except:
                    continue
        return None
    
    # ===== –ò–°–¢–û–ß–ù–ò–ö 1: –ë–∞–Ω–∫–∏.—Ä—É =====
    def parse_banki_ru(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –ë–∞–Ω–∫–∏.—Ä—É —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏"""
        print("  [1/7] –ü–∞—Ä—Å–∏–º –ë–∞–Ω–∫–∏.—Ä—É...")
        
        for attempt in range(3):
            proxy = self.proxy_manager.get_proxy()
            if not proxy:
                continue
            
            try:
                session = requests.Session()
                session.proxies.update(proxy)
                session.headers.update({'User-Agent': self.get_ua()})
                
                # –ó–∞—Ö–æ–¥–∏–º –Ω–∞ –≥–ª–∞–≤–Ω—É—é
                session.get('https://www.banki.ru/', timeout=10)
                time.sleep(1)
                
                # –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –∏–ø–æ—Ç–µ–∫–æ–π
                url = "https://www.banki.ru/products/ipoteka/"
                response = session.get(url, timeout=10)
                
                if response.status_code == 200:
                    soup = BeautifulSoup(response.text, 'html.parser')
                    found = 0
                    
                    # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –±–∞–Ω–∫–∞–º–∏
                    rows = soup.find_all('tr', {'data-test': 'row'})
                    if not rows:
                        rows = soup.find_all('tr', class_=re.compile('row|product'))
                    
                    for row in rows[:20]:
                        try:
                            # –ù–∞–∑–≤–∞–Ω–∏–µ –±–∞–Ω–∫–∞
                            name_tag = row.find(['a', 'span'], class_=re.compile('name|title'))
                            if not name_tag:
                                continue
                            
                            bank_name = name_tag.get_text().strip()
                            bank_name = re.sub(r'\s+', ' ', bank_name)
                            
                            # –°—Ç–∞–≤–∫–∞
                            row_text = row.get_text()
                            rate = self.extract_rate(row_text)
                            
                            if bank_name and rate:
                                self.all_rates[bank_name] = rate
                                found += 1
                                print(f"      ‚úì {bank_name[:20]}: {rate}%")
                                
                        except:
                            continue
                    
                    if found > 0:
                        print(f"    ‚úÖ –ë–∞–Ω–∫–∏.—Ä—É: {found} –±–∞–Ω–∫–æ–≤")
                        return True
                    else:
                        self.proxy_manager.report_bad(proxy)
                        
            except Exception as e:
                print(f"    ‚ö†Ô∏è –û—à–∏–±–∫–∞: {e}")
                self.proxy_manager.report_bad(proxy)
            
            time.sleep(1)
        
        print("    ‚ùå –ë–∞–Ω–∫–∏.—Ä—É –Ω–µ —Å–ø–∞—Ä—Å–∏–ª—Å—è")
        return False
    
    # ===== –ò–°–¢–û–ß–ù–ò–ö 2: –°—Ä–∞–≤–Ω–∏.—Ä—É =====
    def parse_sravni_ru(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –°—Ä–∞–≤–Ω–∏.—Ä—É"""
        print("  [2/7] –ü–∞—Ä—Å–∏–º –°—Ä–∞–≤–Ω–∏.—Ä—É...")
        
        try:
            url = "https://www.sravni.ru/ipoteka/"
            headers = {'User-Agent': self.get_ua()}
            
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                found = 0
                
                # –ò—â–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ –±–∞–Ω–∫–æ–≤
                cards = soup.find_all('div', class_=re.compile('product-item|bank-card|offer'))
                
                if not cards:
                    cards = soup.find_all('article', class_=re.compile('product'))
                
                for card in cards[:15]:
                    try:
                        card_text = card.get_text()
                        
                        # –ù–∞–∑–≤–∞–Ω–∏–µ –±–∞–Ω–∫–∞
                        bank_match = re.search(r'([–ê-–Ø][–∞-—è]+(?:\s+[–ê-–Ø][–∞-—è]+)*)', card_text)
                        if not bank_match:
                            continue
                        
                        bank_name = bank_match.group(1).strip()
                        
                        # –°—Ç–∞–≤–∫–∞
                        rate = self.extract_rate(card_text)
                        
                        if bank_name and rate:
                            self.all_rates[bank_name] = rate
                            found += 1
                            print(f"      ‚úì {bank_name[:20]}: {rate}%")
                            
                    except:
                        continue
                
                if found > 0:
                    print(f"    ‚úÖ –°—Ä–∞–≤–Ω–∏.—Ä—É: {found} –±–∞–Ω–∫–æ–≤")
                    return True
                else:
                    print("    ‚ö†Ô∏è –ë–∞–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            else:
                print(f"    ‚ö†Ô∏è –°—Ç–∞—Ç—É—Å {response.status_code}")
                
        except Exception as e:
            print(f"    ‚ùå –û—à–∏–±–∫–∞: {e}")
        
        return False
    
    # ===== –ò–°–¢–û–ß–ù–ò–ö 3: –ú–ë–ö =====
    def parse_mbk_ru(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –ú–ë–ö"""
        print("  [3/7] –ü–∞—Ä—Å–∏–º –ú–ë–ö...")
        
        try:
            url = "https://www.mbk.ru/ipoteka/"
            headers = {'User-Agent': self.get_ua()}
            
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                found = 0
                
                # –ò—â–µ–º –±–ª–æ–∫–∏ —Å –±–∞–Ω–∫–∞–º–∏
                blocks = soup.find_all('div', class_=re.compile('bank-item|product-card'))
                
                for block in blocks[:15]:
                    try:
                        text = block.get_text()
                        
                        bank_match = re.search(r'([–ê-–Ø][–∞-—è]+(?:\s+[–ê-–Ø][–∞-—è]+)*)', text)
                        if not bank_match:
                            continue
                        
                        bank_name = bank_match.group(1).strip()
                        rate = self.extract_rate(text)
                        
                        if bank_name and rate:
                            self.all_rates[bank_name] = rate
                            found += 1
                            print(f"      ‚úì {bank_name[:20]}: {rate}%")
                            
                    except:
                        continue
                
                if found > 0:
                    print(f"    ‚úÖ –ú–ë–ö: {found} –±–∞–Ω–∫–æ–≤")
                    return True
                    
        except Exception as e:
            print(f"    ‚ùå –û—à–∏–±–∫–∞: {e}")
        
        return False
    
    # ===== –ò–°–¢–û–ß–ù–ò–ö 4: –í—ã–±–µ—Ä—É.—Ä—É =====
    def parse_vbr_ru(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –í—ã–±–µ—Ä—É.—Ä—É"""
        print("  [4/7] –ü–∞—Ä—Å–∏–º –í—ã–±–µ—Ä—É.—Ä—É...")
        
        try:
            url = "https://www.vbr.ru/banki/ipoteka/"
            headers = {'User-Agent': self.get_ua()}
            
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                found = 0
                
                items = soup.find_all('div', class_=re.compile('b-list-item'))
                
                for item in items[:15]:
                    try:
                        text = item.get_text()
                        
                        bank_match = re.search(r'([–ê-–Ø][–∞-—è]+(?:\s+[–ê-–Ø][–∞-—è]+)*)', text)
                        if not bank_match:
                            continue
                        
                        bank_name = bank_match.group(1).strip()
                        rate = self.extract_rate(text)
                        
                        if bank_name and rate:
                            self.all_rates[bank_name] = rate
                            found += 1
                            print(f"      ‚úì {bank_name[:20]}: {rate}%")
                            
                    except:
                        continue
                
                if found > 0:
                    print(f"    ‚úÖ –í—ã–±–µ—Ä—É.—Ä—É: {found} –±–∞–Ω–∫–æ–≤")
                    return True
                    
        except Exception as e:
            print(f"    ‚ùå –û—à–∏–±–∫–∞: {e}")
        
        return False
    
    # ===== –ò–°–¢–û–ß–ù–ò–ö 5: –§–∏–Ω—É—Å–ª—É–≥–∏ =====
    def parse_finuslugi_ru(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –§–∏–Ω—É—Å–ª—É–≥–∏"""
        print("  [5/7] –ü–∞—Ä—Å–∏–º –§–∏–Ω—É—Å–ª—É–≥–∏...")
        
        try:
            url = "https://finuslugi.ru/mortgages"
            headers = {'User-Agent': self.get_ua()}
            
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                found = 0
                
                cards = soup.find_all('div', class_=re.compile('card|product'))
                
                for card in cards[:15]:
                    try:
                        text = card.get_text()
                        
                        bank_match = re.search(r'([–ê-–Ø][–∞-—è]+(?:\s+[–ê-–Ø][–∞-—è]+)*)', text)
                        if not bank_match:
                            continue
                        
                        bank_name = bank_match.group(1).strip()
                        rate = self.extract_rate(text)
                        
                        if bank_name and rate:
                            self.all_rates[bank_name] = rate
                            found += 1
                            print(f"      ‚úì {bank_name[:20]}: {rate}%")
                            
                    except:
                        continue
                
                if found > 0:
                    print(f"    ‚úÖ –§–∏–Ω—É—Å–ª—É–≥–∏: {found} –±–∞–Ω–∫–æ–≤")
                    return True
                    
        except Exception as e:
            print(f"    ‚ùå –û—à–∏–±–∫–∞: {e}")
        
        return False
    
    # ===== –ò–°–¢–û–ß–ù–ò–ö 6: –ë–∞–Ω–∫–ò–Ω—Ñ–æ—Ä–º =====
    def parse_bankinform_ru(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –ë–∞–Ω–∫–ò–Ω—Ñ–æ—Ä–º"""
        print("  [6/7] –ü–∞—Ä—Å–∏–º –ë–∞–Ω–∫–ò–Ω—Ñ–æ—Ä–º...")
        
        try:
            url = "https://bankinform.ru/bank/ipoteka"
            headers = {'User-Agent': self.get_ua()}
            
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                found = 0
                
                rows = soup.find_all('tr')
                
                for row in rows[1:16]:
                    try:
                        text = row.get_text()
                        
                        bank_match = re.search(r'([–ê-–Ø][–∞-—è]+(?:\s+[–ê-–Ø][–∞-—è]+)*)', text)
                        if not bank_match:
                            continue
                        
                        bank_name = bank_match.group(1).strip()
                        rate = self.extract_rate(text)
                        
                        if bank_name and rate:
                            self.all_rates[bank_name] = rate
                            found += 1
                            print(f"      ‚úì {bank_name[:20]}: {rate}%")
                            
                    except:
                        continue
                
                if found > 0:
                    print(f"    ‚úÖ –ë–∞–Ω–∫–ò–Ω—Ñ–æ—Ä–º: {found} –±–∞–Ω–∫–æ–≤")
                    return True
                    
        except Exception as e:
            print(f"    ‚ùå –û—à–∏–±–∫–∞: {e}")
        
        return False
    
    # ===== –ò–°–¢–û–ß–ù–ò–ö 7: –Ø–Ω–¥–µ–∫—Å.–ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å =====
    def parse_yandex_ru(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –Ø–Ω–¥–µ–∫—Å.–ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å"""
        print("  [7/7] –ü–∞—Ä—Å–∏–º –Ø–Ω–¥–µ–∫—Å.–ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å...")
        
        try:
            url = "https://realty.yandex.ru/ipoteka/programs/"
            headers = {'User-Agent': self.get_ua()}
            
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                found = 0
                
                blocks = soup.find_all('div', class_=re.compile('program|card'))
                
                for block in blocks[:10]:
                    try:
                        text = block.get_text()
                        
                        bank_match = re.search(r'([–ê-–Ø][–∞-—è]+(?:\s+[–ê-–Ø][–∞-—è]+)*)', text)
                        if not bank_match:
                            continue
                        
                        bank_name = bank_match.group(1).strip()
                        rate = self.extract_rate(text)
                        
                        if bank_name and rate:
                            self.all_rates[bank_name] = rate
                            found += 1
                            print(f"      ‚úì {bank_name[:20]}: {rate}%")
                            
                    except:
                        continue
                
                if found > 0:
                    print(f"    ‚úÖ –Ø–Ω–¥–µ–∫—Å: {found} –±–∞–Ω–∫–æ–≤")
                    return True
                    
        except Exception as e:
            print(f"    ‚ùå –û—à–∏–±–∫–∞: {e}")
        
        return False
    
    # ===== –û–¢–î–ï–õ–¨–ù–´–ï –ë–ê–ù–ö–ò =====
    def parse_individual_banks(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –±–∞–Ω–∫–æ–≤"""
        print("  –ü–∞—Ä—Å–∏–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ –±–∞–Ω–∫–∏...")
        
        # –°–±–µ—Ä
        try:
            url = "https://www.sberbank.ru/ru/person/credits/home/buying_complete_house"
            response = requests.get(url, headers={'User-Agent': self.get_ua()}, timeout=10)
            if response.status_code == 200:
                rate = self.extract_rate(response.text)
                if rate:
                    self.all_rates['–°–±–µ—Ä–±–∞–Ω–∫'] = rate
                    print(f"    ‚úì –°–±–µ—Ä: {rate}%")
        except:
            pass
        
        time.sleep(1)
        
        # –í–¢–ë
        try:
            url = "https://www.vtb.ru/personal/ipoteka/"
            response = requests.get(url, headers={'User-Agent': self.get_ua()}, timeout=10)
            if response.status_code == 200:
                rate = self.extract_rate(response.text)
                if rate:
                    self.all_rates['–í–¢–ë'] = rate
                    print(f"    ‚úì –í–¢–ë: {rate}%")
        except:
            pass
        
        time.sleep(1)
        
        # –ê–ª—å—Ñ–∞
        try:
            url = "https://alfabank.ru/get-money/mortgage/"
            response = requests.get(url, headers={'User-Agent': self.get_ua()}, timeout=10)
            if response.status_code == 200:
                rate = self.extract_rate(response.text)
                if rate:
                    self.all_rates['–ê–ª—å—Ñ–∞-–ë–∞–Ω–∫'] = rate
                    print(f"    ‚úì –ê–ª—å—Ñ–∞: {rate}%")
        except:
            pass
    
    # ===== –ì–õ–ê–í–ù–´–ô –°–ë–û–† =====
    def collect_all_rates(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ 7 –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        print("\n  üöÄ –ó–ê–ü–£–°–ö 7 –ò–°–¢–û–ß–ù–ò–ö–û–í")
        
        # –ò—Å—Ç–æ—á–Ω–∏–∫ 1-2: –ë–∞–Ω–∫–∏.—Ä—É –∏ –°—Ä–∞–≤–Ω–∏.—Ä—É
        self.parse_banki_ru()
        time.sleep(2)
        self.parse_sravni_ru()
        time.sleep(2)
        
        # –ò—Å—Ç–æ—á–Ω–∏–∫ 3-5: –û—Å—Ç–∞–ª—å–Ω—ã–µ –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä—ã
        self.parse_mbk_ru()
        time.sleep(1)
        self.parse_vbr_ru()
        time.sleep(1)
        self.parse_finuslugi_ru()
        time.sleep(1)
        
        # –ò—Å—Ç–æ—á–Ω–∏–∫ 6-7: –ï—â—ë –¥–≤–∞
        self.parse_bankinform_ru()
        time.sleep(1)
        self.parse_yandex_ru()
        time.sleep(1)
        
        # –û—Ç–¥–µ–ª—å–Ω—ã–µ –±–∞–Ω–∫–∏ –¥–ª—è —Å–≤–µ—Ä–∫–∏
        self.parse_individual_banks()
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –±–∞–Ω–∫–æ–≤ (–æ—Å—Ç–∞–≤–ª—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Å—Ç–∞–≤–∫–∏)
        unique_rates = {}
        for bank, rate in self.all_rates.items():
            bank_key = bank.lower()
            bank_key = re.sub(r'[¬´¬ª"]', '', bank_key)
            bank_key = bank_key.replace('–±–∞–Ω–∫', '').replace('–±a–Ω–∫', '').strip()
            
            found = False
            for existing_bank, existing_rate in unique_rates.items():
                if bank_key in existing_bank.lower() or existing_bank.lower() in bank_key:
                    unique_rates[existing_bank] = min(rate, existing_rate)
                    found = True
                    break
            
            if not found:
                unique_rates[bank] = rate
        
        self.all_rates = unique_rates
        
        print(f"\n  ‚úÖ –í–°–ï–ì–û –£–ù–ò–ö–ê–õ–¨–ù–´–• –ë–ê–ù–ö–û–í: {len(self.all_rates)}")
        return self.all_rates

# ===== –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï =====
def format_message(rates_dict):
    if not rates_dict:
        return "üòî –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–≤–∫–∏"
    
    rates_list = [(bank, rate) for bank, rate in rates_dict.items()]
    rates_list.sort(key=lambda x: x[1])
    
    top_rates = rates_list[:20]
    min_bank, min_rate = rates_list[0]
    
    text = f"""
üè† <b>–ò–ø–æ—Ç–µ–∫–∞ —Å–µ–≥–æ–¥–Ω—è: –ú–ò–ù–ò–ú–ê–õ–¨–ù–ê–Ø –°–¢–ê–í–ö–ê</b>

üî• <b>–õ—É—á—à–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ:</b>
‚Ä¢ {min_bank} ‚Äî <b>{min_rate}%</b>

üìä <b>–¢–æ–ø-20 –±–∞–Ω–∫–æ–≤:</b>

"""
    
    for i, (bank, rate) in enumerate(top_rates, 1):
        if i == 1:
            text += f"ü•á {bank} ‚Äî {rate}%\n"
        elif i == 2:
            text += f"ü•à {bank} ‚Äî {rate}%\n"
        elif i == 3:
            text += f"ü•â {bank} ‚Äî {rate}%\n"
        else:
            text += f"‚Ä¢ {bank} ‚Äî {rate}%\n"
    
    text += f"""

üìÖ {datetime.now().strftime('%d.%m.%Y %H:%M')} (–ú–°–ö)
üìä –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {len(rates_list)} –±–∞–Ω–∫–æ–≤
üîÑ –ò—Å—Ç–æ—á–Ω–∏–∫–∏: 7 –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–æ–≤ + –æ—Ç–¥–µ–ª—å–Ω—ã–µ –±–∞–Ω–∫–∏
"""
    
    return text

# ===== –û–¢–ü–†–ê–í–ö–ê =====
def send_to_channel(text):
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    data = {
        "chat_id": CHANNEL_ID,
        "text": text,
        "parse_mode": "HTML"
    }
    
    try:
        response = requests.post(url, data=data, timeout=10)
        if response.status_code == 200:
            print("  ‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ –∫–∞–Ω–∞–ª!")
    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")

# ===== –ì–õ–ê–í–ù–ê–Ø =====
def main():
    print("=" * 60)
    print("üöÄ MEGA PARSER - 7 –ò–°–¢–û–ß–ù–ò–ö–û–í")
    print(f"üìÖ {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}")
    print("=" * 60)
    
    if not BOT_TOKEN or not CHANNEL_ID:
        print("‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫")
        return
    
    parser = MegaParser()
    rates = parser.collect_all_rates()
    
    print(f"\nüìä –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –±–∞–Ω–∫–æ–≤: {len(rates)}")
    
    if len(rates) < 5:
        print("‚ö†Ô∏è –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö, –¥–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∞—Å–Ω—ã–µ...")
        fallback = {
            '–°–±–µ—Ä–±–∞–Ω–∫': 21.0, '–í–¢–ë': 20.1, '–ê–ª—å—Ñ–∞-–ë–∞–Ω–∫': 20.5,
            '–¢-–ë–∞–Ω–∫': 16.9, '–£—Ä–∞–ª—Å–∏–±': 18.79, '–ü—Ä–æ–º—Å–≤—è–∑—å–±–∞–Ω–∫': 19.49
        }
        for bank, rate in fallback.items():
            if bank not in rates:
                rates[bank] = rate
    
    message = format_message(rates)
    send_to_channel(message)
    print("\n‚úÖ –ì–û–¢–û–í–û")

if __name__ == "__main__":
    main()